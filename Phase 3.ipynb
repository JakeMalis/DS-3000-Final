{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8255858b",
   "metadata": {},
   "source": [
    "# Phase III: First ML Model Proof of Concept w/ Discussion of Ethical Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928acd09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5783c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flights_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_flights.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "flights_df = pd.read_parquet(\"cleaned_flights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1783ef1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flights_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the hour from the 'DATE' column and create a new column 'DEPARTURE_HOUR'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m flights_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEPARTURE_HOUR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mflights_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Filter the DataFrame to include only delayed flights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m delayed_flights \u001b[38;5;241m=\u001b[39m flights_df[flights_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mARRIVAL_DELAY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flights_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the hour from the 'DATE' column and create a new column 'DEPARTURE_HOUR'\n",
    "flights_df['DEPARTURE_HOUR'] = flights_df['DATE'].dt.hour\n",
    "\n",
    "# Filter the DataFrame to include only delayed flights\n",
    "delayed_flights = flights_df[flights_df['ARRIVAL_DELAY'] > 0]\n",
    "delayed_flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc2907",
   "metadata": {},
   "source": [
    "## Numpy ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192d5b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1e9dcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delayed_flights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Standardize numeric columns including DISTANCE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEPARTURE_HOUR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAY_OF_WEEK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDISTANCE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     col_mean \u001b[38;5;241m=\u001b[39m \u001b[43mdelayed_flights\u001b[49m[col]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m     col_std  \u001b[38;5;241m=\u001b[39m delayed_flights[col]\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m      5\u001b[0m     delayed_flights[col] \u001b[38;5;241m=\u001b[39m (delayed_flights[col] \u001b[38;5;241m-\u001b[39m col_mean) \u001b[38;5;241m/\u001b[39m col_std\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delayed_flights' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize numeric columns including DISTANCE\n",
    "for col in ['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE']:\n",
    "    col_mean = delayed_flights[col].mean()\n",
    "    col_std  = delayed_flights[col].std()\n",
    "    delayed_flights[col] = (delayed_flights[col] - col_mean) / col_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e1b36c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delayed_flights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract features: numeric and categorical features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m numeric_feats \u001b[38;5;241m=\u001b[39m \u001b[43mdelayed_flights\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEPARTURE_HOUR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAY_OF_WEEK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDISTANCE\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      3\u001b[0m categorical_feats \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(delayed_flights[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAIRLINE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGIN_AIRPORT\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([numeric_feats, categorical_feats])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delayed_flights' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract features: numeric and categorical features\n",
    "numeric_feats = delayed_flights[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE']].values\n",
    "categorical_feats = pd.get_dummies(delayed_flights[['AIRLINE', 'ORIGIN_AIRPORT']]).values\n",
    "X = np.hstack([numeric_feats, categorical_feats])\n",
    "y = delayed_flights['ARRIVAL_DELAY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple train/test split (e.g. 80% train, 20% test)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test,  y_test  = X[split_idx:], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86390a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of 1s for the intercept\n",
    "ones_train = np.ones((X_train.shape[0], 1))\n",
    "X_train_design = np.hstack((ones_train, X_train))\n",
    "\n",
    "ones_test = np.ones((X_test.shape[0], 1))\n",
    "X_test_design = np.hstack((ones_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e79e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Normal equation using pseudo-inverse to handle singular matrix: w = (XᵀX)⁺ Xᵀy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(X_train_design\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X_train_design) \u001b[38;5;241m@\u001b[39m (X_train_design\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y_train)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m X_test_design \u001b[38;5;241m@\u001b[39m w\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Normal equation using pseudo-inverse to handle singular matrix: w = (XᵀX)⁺ Xᵀy\n",
    "w = np.linalg.pinv(X_train_design.T @ X_train_design) @ (X_train_design.T @ y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = X_test_design @ w\n",
    "\n",
    "# Evaluate with MSE\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"Intercept:\", w[0])\n",
    "\n",
    "# Compute R²\n",
    "ss_res = np.sum((y_test - y_pred) ** 2)\n",
    "ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e937f",
   "metadata": {},
   "source": [
    "### Find optimal and least optimal flight features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept\n",
    "ones = np.ones((X.shape[0], 1))\n",
    "X_design = np.hstack((ones, X))\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = X_design @ w\n",
    "\n",
    "# Find indices for min/max predicted delays\n",
    "best_idx = np.argmin(y_pred)\n",
    "worst_idx = np.argmax(y_pred)\n",
    "\n",
    "# Retrieve flights\n",
    "best_flight = delayed_flights.iloc[best_idx]\n",
    "worst_flight = delayed_flights.iloc[worst_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c16e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best flight (lowest predicted delay):\")\n",
    "print(best_flight[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK']])\n",
    "print(\"Predicted delay (minutes):\", y_pred[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Worst flight (highest predicted delay):\")\n",
    "print(worst_flight[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK']])\n",
    "print(\"Predicted delay (minutes):\", y_pred[worst_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd123904",
   "metadata": {},
   "source": [
    "## NumPy Quadratic ML Model\n",
    "*Note*: It was way too hard to use categorical data with NumPy for non-linear models, so we will do that in the future with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic feature expansion\n",
    "month_sq = delayed_flights['MONTH'] ** 2\n",
    "sched_dep_sq = delayed_flights['DEPARTURE_HOUR'] ** 2\n",
    "dow_sq = delayed_flights['DAY_OF_WEEK'] ** 2\n",
    "distance_sq = delayed_flights['DISTANCE'] ** 2\n",
    "interaction_1 = delayed_flights['MONTH'] * delayed_flights['DEPARTURE_HOUR']\n",
    "interaction_2 = delayed_flights['MONTH'] * delayed_flights['DAY_OF_WEEK']\n",
    "interaction_3 = delayed_flights['DEPARTURE_HOUR'] * delayed_flights['DAY_OF_WEEK']\n",
    "interaction_4 = delayed_flights['MONTH'] * delayed_flights['DISTANCE']\n",
    "interaction_5 = delayed_flights['DEPARTURE_HOUR'] * delayed_flights['DISTANCE']\n",
    "interaction_6 = delayed_flights['DAY_OF_WEEK'] * delayed_flights['DISTANCE']\n",
    "\n",
    "# Combine original and new features\n",
    "X_quad = np.column_stack([\n",
    "    delayed_flights['MONTH'],\n",
    "    delayed_flights['DEPARTURE_HOUR'],\n",
    "    delayed_flights['DAY_OF_WEEK'],\n",
    "    delayed_flights['DISTANCE'],\n",
    "    month_sq,\n",
    "    sched_dep_sq,\n",
    "    dow_sq,\n",
    "    distance_sq,\n",
    "    interaction_1,\n",
    "    interaction_2,\n",
    "    interaction_3,\n",
    "    interaction_4,\n",
    "    interaction_5,\n",
    "    interaction_6\n",
    "])\n",
    "y_quad = delayed_flights['ARRIVAL_DELAY'].values\n",
    "\n",
    "# Train/test split\n",
    "split_idx = int(0.8 * len(X_quad))\n",
    "X_train_quad, y_train_quad = X_quad[:split_idx], y_quad[:split_idx]\n",
    "X_test_quad,  y_test_quad  = X_quad[split_idx:], y_quad[split_idx:]\n",
    "\n",
    "# Add intercept\n",
    "ones_train_quad = np.ones((X_train_quad.shape[0], 1))\n",
    "X_train_design_quad = np.hstack((ones_train_quad, X_train_quad))\n",
    "\n",
    "ones_test_quad = np.ones((X_test_quad.shape[0], 1))\n",
    "X_test_design_quad = np.hstack((ones_test_quad, X_test_quad))\n",
    "\n",
    "# Normal equation for quadratic features\n",
    "w_quad = np.linalg.inv(X_train_design_quad.T @ X_train_design_quad) @ (X_train_design_quad.T @ y_train_quad)\n",
    "\n",
    "# Predictions\n",
    "y_pred_quad = X_test_design_quad @ w_quad\n",
    "mse_quad = np.mean((y_test_quad - y_pred_quad)**2)\n",
    "print(\"Quadratic MSE:\", mse_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72719bdd",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc78c12",
   "metadata": {},
   "source": [
    "What we found while analyzing the results is that while the model may not be effective in predicting delays, it still happens to have a resonable understanding of the data. The model's ability to see the trend of most vs least optimal flights is rather impressive, and the reason it fails to make accurate predictions is that it doesn't have a full scope of the largest factor impacting flights: weather data. We've already begun work adding in weather data as well as using larger models featuring gradient boosting to hopefully generate better predictions when given the full picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333d218",
   "metadata": {},
   "source": [
    "## Ethical Considerations\n",
    "\n",
    "Our data set has limited ethical qualms as it is based off factual data that is not suseptible to bias. The data we are observing is mostly time stamps (day of week, month of year, time of day, etc) which leaves little room for systemic biases infleuncing our conclusions. The resulting data, delay times, are also not choices made by humans (think of, contrastingly, jury decisions in criminal trials), and therefore are unlikely if not impossible to reflect any systemic discrimination or influences. Thus, training a model on this data shall not perpetuate any biases, negative or positive, that could cause harm to people. Any damage done to aviation companies based on the model's predictions would reflect their own quality of service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
