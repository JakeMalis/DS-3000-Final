{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delay Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned flight data\n",
    "flights_df = pd.read_parquet(\"cleaned_flights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour from the 'DATE' column and create a new column 'DEPARTURE_HOUR'\n",
    "flights_df['DEPARTURE_HOUR'] = flights_df['DATE'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in 'DAILY_SNOWFALL' with 0\n",
    "flights_df['DAILY_SNOWFALL'] = flights_df['DAILY_SNOWFALL'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only delayed flights from flights_df\n",
    "delayed_flights = flights_df[flights_df['ARRIVAL_DELAY'] > 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLX Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric columns for sklearn models\n",
    "for col in ['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE']:\n",
    "    col_mean = delayed_flights[col].mean()\n",
    "    col_std  = delayed_flights[col].std()\n",
    "    delayed_flights[col] = (delayed_flights[col] - col_mean) / col_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for sklearn models\n",
    "numeric_feats = delayed_flights[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE', 'DAILY_SNOWFALL']].values\n",
    "categorical_feats = pd.get_dummies(delayed_flights[['AIRLINE', 'origin_airport/AIRPORT', 'destination_airport/AIRPORT']]).values\n",
    "X = np.hstack([numeric_feats, categorical_feats])\n",
    "y = delayed_flights['ARRIVAL_DELAY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * X.shape[0])\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to MLX arrays\n",
    "X_train_mx = mx.array(X_train, dtype=mx.float32)\n",
    "y_train_mx = mx.array(y_train, dtype=mx.float32).reshape(-1, 1)\n",
    "X_test_mx  = mx.array(X_test, dtype=mx.float32)\n",
    "y_test_mx  = mx.array(y_test, dtype=mx.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Feedforward Model\n",
    "class FlightDelayPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.layer3 = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = mx.maximum(self.layer1(x), 0) # ReLU activation\n",
    "        x = mx.maximum(self.layer2(x), 0) # ReLU activation\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_features = X_train_mx.shape[1]\n",
    "model = FlightDelayPredictor(input_dim=input_features)\n",
    "mx.eval(model.parameters()) # Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss and Gradient Function\n",
    "def mse_loss(model, x, y):\n",
    "    return mx.mean(mx.square(model(x) - y))\n",
    "\n",
    "# Get the function that calculates loss and gradients\n",
    "loss_and_grad_fn = nn.value_and_grad(model, mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Optimizer\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 20\n",
    "batch_size = 256\n",
    "num_samples = X_train_mx.shape[0]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    # Create batches\n",
    "    permutation = mx.array(np.random.permutation(num_samples))\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_indices = permutation[i:i+batch_size]\n",
    "        X_batch = X_train_mx[batch_indices]\n",
    "        y_batch = y_train_mx[batch_indices]\n",
    "\n",
    "        # Calculate loss and gradients for the batch\n",
    "        loss, grads = loss_and_grad_fn(model, X_batch, y_batch)\n",
    "\n",
    "        # Update model parameters and optimizer state\n",
    "        optimizer.update(model, grads)\n",
    "\n",
    "        # Force evaluation\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "        epoch_loss += loss.item() * X_batch.shape[0]\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / num_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions (ensure model is in eval mode if using dropout/batchnorm, though not used here)\n",
    "test_predictions_mx = model(X_test_mx)\n",
    "test_loss = mse_loss(model, X_test_mx, y_test_mx)\n",
    "mx.eval(test_predictions_mx, test_loss) # Evaluate predictions and loss\n",
    "\n",
    "print(f\"Test MSE Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "# Print RMSE\n",
    "rmse = np.sqrt(test_loss.item())\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Optional: Calculate R2 score using sklearn\n",
    "test_predictions_np = np.array(test_predictions_mx)\n",
    "y_test_np = np.array(y_test_mx)\n",
    "r2 = r2_score(y_test_np, test_predictions_np)\n",
    "print(f\"Test R2 Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
