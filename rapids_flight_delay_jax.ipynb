{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYeGwsGlHn4r"
      },
      "source": [
        "# Flight Delay Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGU783tIHn4r"
      },
      "source": [
        "## Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xZIAawFewOax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLM6nf18Hn4s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufnWNFkcHn4s"
      },
      "outputs": [],
      "source": [
        "# Load the cleaned flight data\n",
        "flights_df = pd.read_parquet(\"/content/drive/MyDrive/cleaned_flights.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08P9Xda7Hn4s"
      },
      "outputs": [],
      "source": [
        "# Extract the hour from the 'DATE' column and create a new column 'DEPARTURE_HOUR'\n",
        "flights_df['DEPARTURE_HOUR'] = flights_df['DATE'].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIKLE8sUHn4s"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in 'DAILY_SNOWFALL' with 0\n",
        "flights_df['DAILY_SNOWFALL'] = flights_df['DAILY_SNOWFALL'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xWQhF4hHn4s"
      },
      "outputs": [],
      "source": [
        "# Select only delayed flights from flights_df\n",
        "delayed_flights = flights_df[flights_df['ARRIVAL_DELAY'] > 0].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDK7Mnm3Hn4s"
      },
      "source": [
        "## JAX Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwJcjTTaHn4s"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random, grad, jit, value_and_grad\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9VcgKxMHn4t"
      },
      "outputs": [],
      "source": [
        "# Standardize numeric columns for PyTorch models\n",
        "for col in ['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE']:\n",
        "    col_mean = delayed_flights[col].mean()\n",
        "    col_std  = delayed_flights[col].std()\n",
        "    delayed_flights[col] = (delayed_flights[col] - col_mean) / col_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AiVqdZEHn4t"
      },
      "outputs": [],
      "source": [
        "# Extract features for PyTorch models\n",
        "numeric_feats = delayed_flights[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE', 'DAILY_SNOWFALL']].astype(jnp.float32).values\n",
        "categorical_feats = pd.get_dummies(delayed_flights[['AIRLINE', 'origin_airport/AIRPORT', 'destination_airport/AIRPORT']]).values\n",
        "X = jnp.hstack([numeric_feats, categorical_feats])\n",
        "y = delayed_flights['ARRIVAL_DELAY'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMtUflsVHn4t"
      },
      "outputs": [],
      "source": [
        "# Initialize TPU for JAX\n",
        "jax_devices = jax.devices(\"tpu\")\n",
        "print(f\"Using device: {jax_devices[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtKP4O-HHn4t"
      },
      "outputs": [],
      "source": [
        "# Convert data to JAX arrays\n",
        "X_jax = jnp.array(X, dtype=jnp.float32)\n",
        "y_jax = jnp.array(y, dtype=jnp.float32).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UT9GSABHn4t"
      },
      "outputs": [],
      "source": [
        "# Split data into train/test sets\n",
        "train_size = int(0.8 * len(X_jax))\n",
        "test_size = len(X_jax) - train_size\n",
        "\n",
        "X_train, X_test = X_jax[:train_size], X_jax[train_size:]\n",
        "y_train, y_test = y_jax[:train_size], y_jax[train_size:]\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Function to create batches\n",
        "def create_batches(X, y, batch_size):\n",
        "    n_batches = len(X) // batch_size\n",
        "    for i in range(n_batches):\n",
        "        yield X[i * batch_size: (i + 1) * batch_size], y[i * batch_size: (i + 1) * batch_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e85-RabvHn4t"
      },
      "outputs": [],
      "source": [
        "# Define Feedforward Neural Network in JAX\n",
        "class FeedForwardNN:\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size1 = hidden_size1\n",
        "        self.hidden_size2 = hidden_size2\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.W1 = random.normal(random.PRNGKey(0), (input_size, hidden_size1)) * jnp.sqrt(2.0 / input_size)\n",
        "        self.b1 = jnp.zeros(hidden_size1)\n",
        "        self.W2 = random.normal(random.PRNGKey(1), (hidden_size1, hidden_size2)) * jnp.sqrt(2.0 / hidden_size1)\n",
        "        self.b2 = jnp.zeros(hidden_size2)\n",
        "        self.W3 = random.normal(random.PRNGKey(2), (hidden_size2, output_size)) * jnp.sqrt(2.0 / hidden_size2)\n",
        "        self.b3 = jnp.zeros(output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # First hidden layer\n",
        "        hidden1 = jax.nn.relu(jnp.dot(X, self.W1) + self.b1)\n",
        "        # Second hidden layer\n",
        "        hidden2 = jax.nn.relu(jnp.dot(hidden1, self.W2) + self.b2)\n",
        "        # Output layer\n",
        "        output = jnp.dot(hidden2, self.W3) + self.b3\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doVOo7SfHn4t"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model, define loss function and optimizer\n",
        "input_size = X.shape[1]\n",
        "hidden_size1 = 64  # Example hidden layer size\n",
        "hidden_size2 = 32   # Example second hidden layer size\n",
        "output_size = 1     # Predicting a single value (arrival delay)\n",
        "\n",
        "model = FeedForwardNN(input_size, hidden_size1, hidden_size2, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "def mse_loss(params, X, y):\n",
        "    # Create an instance of the model using the params\n",
        "    model_instance = FeedForwardNN(params[0][0].shape[0], params[0][0].shape[1], params[1][0].shape[1], params[2][0].shape[1])\n",
        "    # Assuming params is a list of tuples: [(W1, b1), (W2, b2), (W3, b3)]\n",
        "\n",
        "    # Update the model's weights and biases with the current params\n",
        "    model_instance.W1, model_instance.b1 = params[0]\n",
        "    model_instance.W2, model_instance.b2 = params[1]\n",
        "    model_instance.W3, model_instance.b3 = params[2]\n",
        "\n",
        "    # Now use the forward method to make predictions\n",
        "    preds = model_instance.forward(X)\n",
        "    return jnp.mean((preds - y) ** 2)\n",
        "\n",
        "# Function to initialize NN parameters\n",
        "def init_nn_params(layer_sizes, rng_key):\n",
        "    '''Initialize the parameters of a feedforward neural network.'''\n",
        "    params = []\n",
        "    keys = random.split(rng_key, len(layer_sizes) - 1)\n",
        "    for in_size, out_size, key in zip(layer_sizes[:-1], layer_sizes[1:], keys):\n",
        "        W = random.normal(key, (in_size, out_size)) * jnp.sqrt(2.0 / in_size)\n",
        "        b = jnp.zeros(out_size)\n",
        "        params.append((W, b))\n",
        "    return params\n",
        "\n",
        "# Update predict function to use forward method\n",
        "def predict(params, X):\n",
        "    model_instance = FeedForwardNN(params[0][0].shape[0], params[0][0].shape[1], params[1][0].shape[1], params[2][0].shape[1])\n",
        "    model_instance.W1, model_instance.b1 = params[0]\n",
        "    model_instance.W2, model_instance.b2 = params[1]\n",
        "    model_instance.W3, model_instance.b3 = params[2]\n",
        "    return model_instance.forward(X)\n",
        "\n",
        "# Define the update step (train_step)\n",
        "@jit\n",
        "def train_step(params, X, y, learning_rate):\n",
        "    \"\"\"Updates model parameters using gradient descent.\"\"\"\n",
        "    loss, grads = value_and_grad(mse_loss)(params, X, y)\n",
        "    # Update parameters\n",
        "    updated_params = []\n",
        "    for param, grad in zip(params, grads):\n",
        "        updated_params.append((param[0] - learning_rate * grad[0],\n",
        "                               param[1] - learning_rate * grad[1]))\n",
        "    return updated_params"
      ],
      "metadata": {
        "id": "JIl9IvqK8zgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3DJ7bqHn4t"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "rng_key = random.PRNGKey(0)\n",
        "layer_sizes = [X_train.shape[1], 128, 64, 1]\n",
        "params = init_nn_params(layer_sizes, rng_key)\n",
        "num_epochs = 20\n",
        "learning_rate = 0.00001\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in create_batches(X_train, y_train, batch_size):\n",
        "        params = train_step(params, X_batch, y_batch, learning_rate)\n",
        "    # Calculate training loss on a subset of the data to reduce memory usage\n",
        "    train_loss = mse_loss(params, X_train[:10000], y_train[:10000])  # Using a subset of 10000 samples\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sy6EsfVHn4t"
      },
      "outputs": [],
      "source": [
        "# Compile the predict function using jit\n",
        "@jit\n",
        "def predict(params, X):\n",
        "    model_instance = FeedForwardNN(params[0][0].shape[0], params[0][0].shape[1], params[1][0].shape[1], params[2][0].shape[1])  # Create model instance\n",
        "    model_instance.W1, model_instance.b1 = params[0]  # Set weights and biases\n",
        "    model_instance.W2, model_instance.b2 = params[1]\n",
        "    model_instance.W3, model_instance.b3 = params[2]\n",
        "    return model_instance.forward(X)  # Use forward method for prediction\n",
        "\n",
        "\n",
        "y_pred = predict(params, X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = jnp.sqrt(mse)  # Assuming np is imported as numpy\n",
        "\n",
        "print(f\"Test R-squared (R2): {r2:.4f}\")\n",
        "print(f\"Test Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Test Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}