{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYeGwsGlHn4r"
      },
      "source": [
        "# Flight Delay Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGU783tIHn4r"
      },
      "source": [
        "## Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLM6nf18Hn4s"
      },
      "outputs": [],
      "source": [
        "import cudf\n",
        "import cupy as cp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufnWNFkcHn4s"
      },
      "outputs": [],
      "source": [
        "# Load the cleaned flight data\n",
        "flights_df = cudf.read_parquet(\"cleaned_flights.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08P9Xda7Hn4s"
      },
      "outputs": [],
      "source": [
        "# Extract the hour from the 'DATE' column and create a new column 'DEPARTURE_HOUR'\n",
        "flights_df['DEPARTURE_HOUR'] = flights_df['DATE'].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIKLE8sUHn4s"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in 'DAILY_SNOWFALL' with 0\n",
        "flights_df['DAILY_SNOWFALL'] = flights_df['DAILY_SNOWFALL'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xWQhF4hHn4s"
      },
      "outputs": [],
      "source": [
        "# Select only delayed flights from flights_df\n",
        "delayed_flights = flights_df[flights_df['ARRIVAL_DELAY'] > 0].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDK7Mnm3Hn4s"
      },
      "source": [
        "## PyTorch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwJcjTTaHn4s"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "from cuml.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9VcgKxMHn4t"
      },
      "outputs": [],
      "source": [
        "# Standardize numeric columns for PyTorch models\n",
        "for col in ['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE']:\n",
        "    col_mean = delayed_flights[col].mean()\n",
        "    col_std  = delayed_flights[col].std()\n",
        "    delayed_flights[col] = (delayed_flights[col] - col_mean) / col_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AiVqdZEHn4t"
      },
      "outputs": [],
      "source": [
        "# Extract features for PyTorch models\n",
        "numeric_feats = delayed_flights[['MONTH', 'DEPARTURE_HOUR', 'DAY_OF_WEEK', 'DISTANCE', 'DAILY_SNOWFALL']].astype(cp.float32).values\n",
        "categorical_feats = cudf.get_dummies(delayed_flights[['AIRLINE', 'origin_airport/AIRPORT', 'destination_airport/AIRPORT']]).values\n",
        "X = cp.hstack([numeric_feats, categorical_feats])\n",
        "y = delayed_flights['ARRIVAL_DELAY'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMtUflsVHn4t"
      },
      "outputs": [],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtKP4O-HHn4t"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_tensor = torch.as_tensor(X, device=device, dtype=torch.float32)\n",
        "# Reshape y to be a 2D tensor (N, 1) for MSELoss\n",
        "y_tensor = torch.as_tensor(y, device=device, dtype=torch.float32).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UT9GSABHn4t"
      },
      "outputs": [],
      "source": [
        "# Create TensorDataset and DataLoader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "# Define train/test split ratio\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e85-RabvHn4t"
      },
      "outputs": [],
      "source": [
        "# Define the Feedforward Neural Network\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.layer_2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.layer_3 = nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doVOo7SfHn4t"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model, define loss function and optimizer\n",
        "input_size = X.shape[1]\n",
        "hidden_size1 = 128  # Example hidden layer size\n",
        "hidden_size2 = 64   # Example second hidden layer size\n",
        "output_size = 1     # Predicting a single value (arrival delay)\n",
        "\n",
        "model = FeedForwardNN(input_size, hidden_size1, hidden_size2, output_size).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3DJ7bqHn4t"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 20 # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move inputs and labels to the correct device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print statistics every 100 batches\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] completed. Average Training Loss: {epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sy6EsfVHn4t"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "model.eval()  # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        all_preds.append(outputs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all predictions and labels\n",
        "all_preds = torch.concatenate(all_preds, dim=0).numpy()\n",
        "all_labels = torch.concatenate(all_labels, dim=0).numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "r2 = r2_score(all_labels, all_preds)\n",
        "mse = mean_squared_error(all_labels, all_preds)\n",
        "rmse = cp.sqrt(mse)\n",
        "\n",
        "print(f'Test R-squared (R2): {r2:.4f}')\n",
        "print(f'Test Mean Squared Error (MSE): {mse:.4f}')\n",
        "print(f'Test Root Mean Squared Error (RMSE): {rmse:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}